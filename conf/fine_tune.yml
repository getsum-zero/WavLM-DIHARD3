model: wavlm
task: count

# log_dir
# gpus

# training
training:
  batch_size: 8
  num_workers: 8
  n_epochs: 200
  gradient_clip: 5
  accumulate_batches: 1      # 在步进优化器之前累积 k 个批次的梯度
  resume_from: exp/wavlm/checkpoint/WavLM-Large.pt

# 数据增强
augmentation:
  # 需要修改，根据每一类的数据量来调整
  # =============================
  probs: [0.7, 0.3]  
  # probs: [0.7187, 0.0787]     
  # =============================

  abs_stats: [-16.7, 7]
  rel_stats: [2.78, 4]


opt:
  lr: 0.00015
  weight_decay: !!float 1e-5


data:
  n_classes: 3
  segment: 500
  fs: 16000
  custom_json_folder:
  data_root_train: /home/getsum/data/DIHARD3/third_dihard_challenge_dev/data/flac
  label_train: /home/getsum/data/DIHARD3/fa_labels/dev
  data_root_val: /home/getsum/data/DIHARD3/third_dihard_challenge_eval/data/flac
  label_val: /home/getsum/data/DIHARD3/fa_labels/eval


feats:
  type: orig # filterbanks actually if num ceps == num mels
  hop_size: 0.02
  frame_size: 0.025
  n_feats: 80
  inject_noise: false
mels:
  n_mels: 40
  n_fft: 400
  win_length: 400
  hop_length: 160
mfcc:
  sample_rate: 16000
  n_mfcc: 40
  log_mels: true
mfcc_kaldi:
  use_energy: false
  sample_frequency: 16000
  num_mel_bins: 80
  num_ceps: 80
  low_freq: 40
  high_freq: -400
  dither: 0.0
fbank_kaldi:
  use_energy: false
  sample_frequency: 16000
  num_mel_bins: 80
  low_freq: 80
  high_freq: -400
  dither: 0.00000001
spectrogram_kaldi:
  sample_frequency: 16000
  dither: 0.0
labels:
  merge_vad: 0.0
  merge_ph: 0.0
  collar_ph: 0.00


